{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model inference\n","This notebook is used to load saved model weights and run inference on sample images"],"metadata":{"id":"vBaB38ltUaxB"}},{"cell_type":"code","source":["# Import libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import random\n","from pathlib import Path\n","import tensorflow as tf\n","from keras import layers\n","from keras import ops\n","from keras import Model\n","import keras\n","\n","target_shape = (75, 75)"],"metadata":{"id":"Les_AgoUuln8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"927akLizuxe4","executionInfo":{"status":"ok","timestamp":1729432625474,"user_tz":-180,"elapsed":46438,"user":{"displayName":"Yara Elmowafy","userId":"03732489502932602378"}},"outputId":"8219df00-e46f-4280-8b16-be419f7e4f53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Preprocessed dataset saved in drive to read directly\n","\n","anchor_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_image.npy'\n","pos_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/pos_image.npy'\n","neg_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/neg_image.npy'\n","gender_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_gender.npy'\n","age_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_age.npy'\n","saved_model_dir = '/content/drive/MyDrive/celebA Dataset/weights'\n","\n","# anchor_path = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/Matching_triplets/anchor_image.npy'\n","# pos_path = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/Matching_triplets/pos_image.npy'\n","# neg_path = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/Matching_triplets/neg_image.npy'\n","# gender_path = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/Matching_triplets/anchor_gender.npy'\n","# age_path = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/Matching_triplets/anchor_age.npy'\n","\n","# saved_model_dir = '/content/drive/MyDrive/Depi/Project/Model_training/celebA Dataset/weights'"],"metadata":{"id":"t0K3FRiuuynt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@keras.saving.register_keras_serializable()\n","class DistanceLayer(layers.Layer):\n","    \"\"\"\n","    This layer is responsible for computing the distance between the anchor\n","    embedding and the positive embedding, and the anchor embedding and the\n","    negative embedding.\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def call(self, anchor, test):\n","        at_distance = ops.sum(tf.square(anchor - test), -1)     # distance between anchor and test images\n","        return at_distance\n"],"metadata":{"id":"8uTfoekUu8pX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load model from saved .keras file"],"metadata":{"id":"Onz4AlOqvDQe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4oBOASjubss"},"outputs":[],"source":["# Load model weight and pass an image for inference\n","complete_model = tf.keras.models.load_model(os.path.join(saved_model_dir, f'model_epoch_30.keras'))\n","# Remove the negative image branch from the model\n","inference_model = Model(complete_model.inputs[:2],\n","                        complete_model.outputs[:3])"]},{"cell_type":"markdown","source":["## Run inference on a sample image"],"metadata":{"id":"DnLCfH0vxBFV"}},{"cell_type":"code","source":["# Load an image from dataset\n","anchor_images = np.load(anchor_path)\n","test_images = np.load(pos_path)\n","test_images_neg = np.load(neg_path)\n","age_all = np.load(age_path)\n","gender_all = np.load(gender_path)"],"metadata":{"id":"XjEc9njgwhvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference_preprocess(image):\n","    \"\"\"\n","    Preprocess the input image by resizing it to the target shape.\n","    \"\"\"\n","    image = tf.image.resize(image, target_shape)\n","    image = tf.image.convert_image_dtype(image, tf.float32)  # Ensure float32\n","    image = tf.expand_dims(image, axis=0, name=None)\n","    return image"],"metadata":{"id":"swvT-T1uwnos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_idx = random.randint(0, len(anchor_images))\n","\n","anchor_image = inference_preprocess(anchor_images[test_idx])\n","test_image = inference_preprocess(test_images[test_idx])\n","test_image_neg = inference_preprocess(test_images_neg[test_idx])"],"metadata":{"id":"ML_J6P-OwvbJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gender, age, distance = inference_model([anchor_image, test_image_neg])"],"metadata":{"id":"5955hHtgwyuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["age_label = 'Young' if age > 0.5 else 'Not young'\n","gender_label = 'Male' if gender > 0.5 else 'Female'\n","verification = 1 if distance > 1 else 1\n","\n","gender_label, age_label, verification"],"metadata":{"id":"oMYUamPbwzNp"},"execution_count":null,"outputs":[]}]}