{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBaB38ltUaxB"
   },
   "source": [
    "# Model inference\n",
    "This notebook is used to load saved model weights and run inference on sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Les_AgoUuln8"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras import Model\n",
    "import keras\n",
    "\n",
    "target_shape = (75, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46438,
     "status": "ok",
     "timestamp": 1729432625474,
     "user": {
      "displayName": "Yara Elmowafy",
      "userId": "03732489502932602378"
     },
     "user_tz": -180
    },
    "id": "927akLizuxe4",
    "outputId": "8219df00-e46f-4280-8b16-be419f7e4f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0K3FRiuuynt"
   },
   "outputs": [],
   "source": [
    "# Preprocessed dataset saved in drive to read directly\n",
    "\n",
    "anchor_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_image.npy'\n",
    "pos_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/pos_image.npy'\n",
    "neg_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/neg_image.npy'\n",
    "gender_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_gender.npy'\n",
    "age_path = '/content/drive/MyDrive/celebA Dataset/Matching_triplets/anchor_age.npy'\n",
    "saved_model_dir = '/content/drive/MyDrive/celebA Dataset/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uTfoekUu8pX"
   },
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, test):\n",
    "        at_distance = ops.sum(tf.square(anchor - test), -1)     # distance between anchor and test images\n",
    "        return at_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Onz4AlOqvDQe"
   },
   "source": [
    "## Load model from saved .keras file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4oBOASjubss"
   },
   "outputs": [],
   "source": [
    "# Load model weight and pass an image for inference\n",
    "complete_model = tf.keras.models.load_model(os.path.join(saved_model_dir, f'model_epoch_30.keras'))\n",
    "# Remove the negative image branch from the model\n",
    "inference_model = Model(complete_model.inputs[:2],\n",
    "                        complete_model.outputs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnLCfH0vxBFV"
   },
   "source": [
    "## Run inference on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjEc9njgwhvR"
   },
   "outputs": [],
   "source": [
    "# Load an image from dataset\n",
    "anchor_images = np.load(anchor_path)\n",
    "test_images = np.load(pos_path)\n",
    "test_images_neg = np.load(neg_path)\n",
    "age_all = np.load(age_path)\n",
    "gender_all = np.load(gender_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swvT-T1uwnos"
   },
   "outputs": [],
   "source": [
    "def inference_preprocess(image):\n",
    "    \"\"\"\n",
    "    Preprocess the input image by resizing it to the target shape.\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, target_shape)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  # Ensure float32\n",
    "    image = tf.expand_dims(image, axis=0, name=None)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML_J6P-OwvbJ"
   },
   "outputs": [],
   "source": [
    "test_idx = random.randint(0, len(anchor_images))\n",
    "\n",
    "anchor_image = inference_preprocess(anchor_images[test_idx])\n",
    "test_image = inference_preprocess(test_images[test_idx])\n",
    "test_image_neg = inference_preprocess(test_images_neg[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5955hHtgwyuc"
   },
   "outputs": [],
   "source": [
    "gender, age, distance = inference_model([anchor_image, test_image_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMYUamPbwzNp"
   },
   "outputs": [],
   "source": [
    "age_label = 'Young' if age > 0.5 else 'Not young'\n",
    "gender_label = 'Male' if gender > 0.5 else 'Female'\n",
    "verification = 1 if distance > 1 else 1\n",
    "\n",
    "gender_label, age_label, verification"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
